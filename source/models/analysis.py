"""
This module defines the Pydantic models for the analysis data structures.
"""

import json
from enum import StrEnum

from pydantic import BaseModel, Field, field_validator


class RedFlagCategory(StrEnum):
    """Enumeration for the categories of identified procurement risks."""

    DIRECTING = "DIRECIONAMENTO"
    COMPETITION_RESTRICTION = "RESTRICAO_COMPETITIVIDADE"
    OVERPRICE = "SOBREPRECO"


class RedFlag(BaseModel):
    """
    Represents a single red flag identified during an audit.
    """

    category: RedFlagCategory = Field(
        ...,
        description=("The category of the irregularity, which must be one of the allowed " "values."),
    )
    description: str = Field(
        ...,
        description=("A short, objective description (in pt-br) of the identified issue."),
    )
    evidence_quote: str = Field(
        ...,
        description=("The exact, literal quote from the document that serves as evidence " "for the finding."),
    )
    auditor_reasoning: str = Field(
        ...,
        description=(
            "A technical justification (in pt-br) from the auditor's "
            "perspective, explaining why the quote represents a risk."
        ),
    )


class Analysis(BaseModel):
    """
    Defines the structured output of a procurement document analysis.
    """

    risk_score: int | None = Field(
        None,
        description=("An integer from 0 to 10 representing the calculated risk level based " "on the findings."),
    )
    risk_score_rationale: str | None = Field(
        None,
        description=("A detailed rationale (in pt-br) explaining the reasoning behind the " "assigned risk score."),
    )
    red_flags: list[RedFlag] = Field(
        default_factory=list,
        description="A list of all red flag objects identified in the document.",
        alias="findings",
    )

    @field_validator("red_flags", mode="before")
    @classmethod
    def parse_red_flags(cls, v):
        if not isinstance(v, list):
            return v
        parsed_flags = []
        for item in v:
            if isinstance(item, str):
                try:
                    parsed_flags.append(json.loads(item))
                except json.JSONDecodeError:
                    # Handle cases where the string is not valid JSON
                    continue
            else:
                parsed_flags.append(item)
        return parsed_flags


class AnalysisResult(BaseModel):
    """Represents the complete result of a procurement analysis, combining the
    AI's findings with operational metadata. This is the object that is
    persisted to the database.

    Attributes:
        procurement_control_number: The unique control number of the procurement
            from the PNCP.
        ai_analysis: The structured analysis and red flags generated by the
            AI model.
        warnings: A list of operational warnings generated during the file
            preparation phase (e.g., file size or count limits exceeded).
        document_hash: A SHA-256 hash of the content of all files included in
            the analysis. Used for idempotency checks.
        original_documents_gcs_path: The base GCS path (folder) where the
            original, unprocessed files for this analysis run are stored.
        processed_documents_gcs_path: The GCS path for the structured JSON
            report generated by the AI model for this analysis run.
    """

    procurement_control_number: str
    version_number: int | None = None
    status: str | None = None
    ai_analysis: Analysis
    warnings: list[str] | None = []
    document_hash: str | None = None
    original_documents_gcs_path: str | None = None
    processed_documents_gcs_path: str | None = None
