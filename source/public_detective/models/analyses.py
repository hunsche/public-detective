"""This module defines the Pydantic models for the analysis data structures."""

from datetime import datetime
from decimal import Decimal
from enum import StrEnum
from typing import Literal
from uuid import UUID

from pydantic import BaseModel, Field


class RedFlagCategory(StrEnum):
    """Enumeration for the categories of an identified procurement risk."""

    DIRECTING = "DIRECIONAMENTO"
    COMPETITION_RESTRICTION = "RESTRICAO_COMPETITIVIDADE"
    OVERPRICE = "SOBREPRECO"
    FRAUD = "FRAUDE"
    IRREGULAR_DOCUMENTATION = "DOCUMENTACAO_IRREGULAR"
    OTHER = "OUTROS"
    SUPERFATURAMENTO = "SUPERFATURAMENTO"


class RedFlag(BaseModel):
    """Represents a single red flag identified during an audit."""

    category: Literal[
        RedFlagCategory.DIRECTING,
        RedFlagCategory.COMPETITION_RESTRICTION,
        RedFlagCategory.OVERPRICE,
        RedFlagCategory.FRAUD,
        RedFlagCategory.IRREGULAR_DOCUMENTATION,
        RedFlagCategory.OTHER,
        RedFlagCategory.SUPERFATURAMENTO,
    ] = Field(
        ...,
        description=("The category of the irregularity, which must be one of the allowed " "values."),
    )
    severity: str | None = Field(
        None,
        description="The severity of the red flag, which can be 'leve', 'moderada', or 'grave'.",
    )
    description: str = Field(
        ...,
        description=("A short, objective description (in pt-br) of the identified issue."),
    )
    evidence_quote: str = Field(
        ...,
        description=("The exact, literal quote from the document that serves as evidence " "for the finding."),
    )
    auditor_reasoning: str = Field(
        ...,
        description=(
            "A technical justification (in pt-br) from the auditor's "
            "perspective, explaining why the quote represents a risk."
        ),
    )


class Analysis(BaseModel):
    """Defines the structured output of a procurement document analysis."""

    risk_score: int | None = Field(
        None,
        ge=0,
        le=10,
        description=("An integer from 0 to 10 representing the calculated risk level based " "on the findings."),
    )
    risk_score_rationale: str | None = Field(
        None,
        description=("A detailed rationale (in pt-br) explaining the reasoning behind the " "assigned risk score."),
    )
    procurement_summary: str | None = Field(
        None,
        description="A concise summary (maximum of 3 sentences, in pt-br) of the procurement's scope.",
    )
    analysis_summary: str | None = Field(
        None,
        description="A concise summary (maximum of 3 sentences, in pt-br) of the overall analysis.",
    )
    red_flags: list[RedFlag] = Field(
        default_factory=list,
        description="A list of all red flag objects identified in the document.",
    )
    price_sources: list[str] | None = Field(
        None,
        description="A list of price sources used by the model for its analysis.",
    )
    seo_keywords: list[str] = Field(
        default_factory=list,
        description="Strategic keywords for SEO (in pt-br) related to the procurement.",
    )


class AnalysisResult(BaseModel):
    """Represents the complete result of a procurement analysis.

    This model combines the AI's findings with essential operational
    metadata. It serves as the primary data structure for storing and
    retrieving the outcome of an analysis from the database.

    Attributes:
        analysis_id: The unique identifier for this specific analysis record.
        procurement_control_number: The unique control number of the
            procurement from the PNCP, linking the analysis to a specific
            public notice.
        version_number: The version of the procurement data that this
            analysis was based on.
        status: The current processing status of the analysis
            (e.g., 'PENDING', 'SUCCESSFUL').
        ai_analysis: The structured analysis and red flags generated by the
            AI model.
        document_hash: A SHA-256 hash of the content of all files included
            in the analysis, used for idempotency checks.
        original_documents_gcs_path: The base GCS path (folder) where the
            original, unprocessed files for this analysis are stored.
        processed_documents_gcs_path: The GCS path for the structured JSON
            report generated by the AI model.
        input_tokens_used: The number of tokens in the prompt sent to the AI.
        output_tokens_used: The number of tokens in the response received
            from the AI.
    """

    analysis_id: UUID | None = None
    procurement_control_number: str
    version_number: int | None = None
    status: str | None = None
    retry_count: int | None = 0
    updated_at: datetime | None = None
    ai_analysis: Analysis
    document_hash: str | None = None
    original_documents_gcs_path: str | None = None
    processed_documents_gcs_path: str | None = None
    analysis_prompt: str
    input_tokens_used: int | None = None
    output_tokens_used: int | None = None
    thinking_tokens_used: int | None = None
    votes_count: int | None = 0
    cost_input_tokens: Decimal | None = None
    cost_output_tokens: Decimal | None = None
    cost_thinking_tokens: Decimal | None = None
    total_cost: Decimal | None = None
